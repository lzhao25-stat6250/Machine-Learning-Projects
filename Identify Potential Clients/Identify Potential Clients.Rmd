---
title: "Identifying Potential Clients"

output:
  pdf_document: default
  word_document: default
---

### Identifying Potential Clients Using C5.0 Decision Trees
The increasing number of marketing campaigns over time has reduced their effects on the general public. First, due to competition, positive response rate to mass campaigns are typically very low, according to a recent study, less than 1% of the contacts will subscribe a term deposit. Second, direct marketing has drawbacks, such as causing negative attitude towards banks due to intrusion of privacy and frequent promotional contacts. In order to save costs and time and improve customer satisfaction, it is important to filter the contacts but keep a certain success rate.
Machine learning has been applied widely to help enterprises to identify potential clients, targets. Nowadays, target marketing is becoming popular, and machine learning is playing a crucial role in its success. In a wide variety of algorithms, Decision tree is widely used in the banking industry or the marketing feild due to their high accuracy and ability to formulate a statistical model in plain language. 
My goal of analysis is to develop a classifier using C5.0 decision trees to predict whether or not a client will subscribe a term deposit with high accuracy but also with high sensitivity. 


## Step 1 - Collecting data ----
I will utilize the Bank Marketing Dataset bank-full.csv from the UCI Machine Learning Repository at http://archive.ics.uci.edu/ml. The data is related with direct marketing campaigns (phone calls) of a Portuguese banking institution. It includes 45,211 examples, 17 variables: a class variable indicating whether a client subscribes a term deposit and 16 features.
The 17 variables are discribed as following:

# Demographic and financial information:
1 - age (numeric)
2 - job : type of job (categorical:'admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown')
3 - marital : marital status (categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)
4 - education (categorical:'basic.4y','basic.6y','basic.9y','high.school','illiterate','professional.course','university.degree','unknown')
5 - default: has credit in default? (categorical: 'no','yes','unknown')
6 - balance (numeric)
7 - housing: has housing loan? (categorical: 'no','yes','unknown')
8 - loan: has personal loan? (categorical: 'no','yes','unknown')

# Related with the last contact of the current campaign:
9 - contact: contact communication type (categorical: 'cellular','telephone') 
10 - month: last contact month of year (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')
11 - day: last contact day of the month (categorical)
12 - duration: last contact duration, in seconds (numeric). 
# Contact history:
13 - campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)
14 - pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)
15 - previous: number of contacts performed before this campaign and for this client (numeric)
16 - poutcome: outcome of the previous marketing campaign (categorical: 'failure', 'nonexistent', 'success')

# Output variable (desired target):
17 - y : has the client subscribed a term deposit? (binary: 'yes','no')


## Step 2: Exploring and preparing the data ----
Explore the data to see whether we can use the data to classify and prepare the data for modeling.

# Import data
Import the data into R

```{r}
#Import the CSV file.
bank <- read.table("bank-full.csv", sep=";", header=T)
str(bank)

```
# Data undersanding and cleaning

```{r}
summary(bank)
# convert day from numeric  to factor
bank$day=factor(bank$day)

```

# Data exploration

Let's take a look at outputs for a couple of features that seem likely to predict if a client is going to subscribes a term deposit.
From the results, features of  education, job, durtion are likely to help to identify potential clients, but age and campaign seem not. The higher the education level is, the more likely a client will subscribe. The students are most likely to response with 28.7% response rate, and retired people, 22.8%,and bule-collars are the least likely to response with 7.3% response rate. The term deposit subscribers talked much longer, with average 537 seconds, than nonsubscriber with  221 seconds in the last contact. The distributions of age and campaign by target variable y seem same.

```{r}
# look at characteristics of the clients
prop.table(table(bank$education, bank$y),1)
prop.table(table(bank$job , bank$y),1)
library('lattice')
histogram(~ age | y, data = bank)

```
```{r}
# look at two characteristics of the contact
tapply(bank$duration,bank$y,summary)
histogram(~ campaign | y, data = bank)
```
look at the class variable. A total of 11.7% of the clients in this dataset subscribed the term deposit. This is a very imbalanced data!

```{r}
# look at the class variable
table(bank$y)/45211
```
# Data preparation - creating training and test datasets
Create training and test data to build models.

```{r}
# split the data frames to training and test data
index=sample(1:nrow(bank),as.integer(.8*nrow(bank)))
bank_train <- bank[index, ]
bank_test  <- bank[-index, ]
```
check the proportion of class variable in training and test datasets. They are close, this appears to be a fairly even split.
```{r}
# check the proportion of class variable
prop.table(table(bank_train$y))
prop.table(table(bank_test$y))
```

## Step 3: Training a model on the data ----
This time, we train a simplest decision tree model on the data. 

```{r}
# build the simplest decision tree

library(C50)
bank_model <- C5.0(bank_train[-17], bank_train$y)
```

```{r}
# display simple facts about the tree
bank_model
```
```{r}
# display detailed information about the tree
summary(bank_model)
```
## Step 4: Evaluating model performance ----
I use confusion matrix, accuracy, KAPPA, sensitivity and ROC curve to evaluating model performance. From the results, the accuracy is 90.3%, which is good if we see it alone. However,since there is 88.3% of  nos in class variable y, the performance is actually fair. KAPPA is 0.466, there is moderate agreement between the classifier's predictions and the actual values. AUC is 0.853, which indicates the classifier is excellent.  The sensitivity is 0.448, the model only correctly identified 44.8 percent of true subscribers. Unfortunately, this type of error is a potentially very costly mistake, as the bank loses money on each term deposit client. We need to improve the result with a bit more effort.

```{r}
# create a factor vector of predictions on test data
bank_pred <- predict(bank_model, bank_test)
predicted_prob <- predict(bank_model, bank_test, type = "prob")

# confusion matrix
library(gmodels)
CrossTable(bank_test$y, bank_pred,
           prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
           dnn = c('actual subscriber', 'predicted subscriber'))

# compute accuracy
accuracy <- mean(bank_test$y==bank_pred)
accuracy

# KAPPA
library(vcd)
Kappa(table(bank_test$y, bank_pred))

# sensitivity
sens <- sum(bank_test$y=="yes" & bank_pred=="yes")/sum(bank_test$y=="yes")
sens

```



```{r}

# ROC Curve

library(ROCR)
library(gplots)
pred <- prediction( predicted_prob[,2], bank_test$y)
perf <- performance(pred, measure = "tpr", x.measure = "fpr")
plot(perf)
abline(a = 0, b = 1, lwd = 2, lty = 2)

perf.auc <- performance(pred, measure = "auc")
unlist(perf.auc@y.values)

```


## Step 5: Improving model performance ----
I will attempt two ways to improve model performance. First, I will employ boosting. This is a process in which many decision trees are built and the trees vote on the best class for each example. Second, we will assign a penalty to different types of errors, in order to discourage a tree from making more costly mistakes. The penalties are designated in a cost matrix, which specifies how much costlier each error is, relative to any other prediction.

# Boosting the accuracy of decision trees
Boosted decision tree with 10 trials, a number that has become the de facto standard. The accuracy is 90.2%, KAPPA is 0.465, AUC is 0.853, and sensitivity is 0.458. These are almost same with the original model's performance. 

```{r}
# boosted decision tree with 10 trials
bank_boost10 <- C5.0(bank_train[-17], bank_train$y,
                       trials = 10)
bank_boost10
summary(bank_boost10)

```

Evaluate the performance
```{r}
bank_boost_pred10 <- predict(bank_boost10, bank_test)
CrossTable(bank_test$y, bank_boost_pred10,
           prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
           dnn = c('actual', 'predicted'))
# compute accuracy
accuracy=mean(bank_test$y==bank_boost_pred10)
accuracy

# KPPA
Kappa(table(bank_test$y, bank_boost_pred10))

# sensitivity
sens <- sum(bank_test$y=="yes" & bank_boost_pred10=="yes")/sum(bank_test$y=="yes")
sens
```


# assign a penalty to different types of errors
Failing to identify a client of a term deposit can be an expensive mistake. Fortunately,the C5.0 algorithm allows us to assign a penalty to different types of errors.

From the results, the accuracy for a C5.0 model with a cost function is 86.7%, KAPPA is 0.515, and sensitivity is 0.812.This model makes a little more mistakes overall: accuracy decreases by 3.5%. However, the types of mistakes are very different. The previous models classified about 45 percent of actual subscrbers correctly, while, 81.2 percent of the actual subscribers were predicted correctly in this model. The sensitivity increases by 36.2%. This trade resulting in a reduction of false negatives at the expense of increasing false positives may be acceptable if our cost estimates were accurate.
The performance of this model meet my goal. Therefore, I prefer this model as my final model.

Training the model
```{r}
# create dimensions for a cost matrix
matrix_dimensions <- list(c("no", "yes"), c("no", "yes"))
names(matrix_dimensions) <- c("predicted", "actual")
matrix_dimensions
```
```{r}
# build the matrix
error_cost <- matrix(c(0, 1, 4, 0), nrow = 2, dimnames = matrix_dimensions)
error_cost
```
```{r}
# apply the cost matrix to the tree
bank_cost <- C5.0(bank_train[-17], bank_train$y,
                    costs = error_cost)

# display simple facts about the tree
bank_cost
```

```{r}
# display detailed information about the tree
summary(bank_cost)

```

```{r}
#Generate predictions on the test data
bank_cost_pred <- predict(bank_cost, bank_test)
```

Evaluation of the cost model
```{r}
# evaluatation the cost model
# confussion matrix
CrossTable(bank_test$y, bank_cost_pred,
           prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
           dnn = c('actual', 'predicted'))

# compute accuracy
accuracy=mean(bank_test$y==bank_cost_pred)
accuracy

# KPPA
Kappa(table(bank_test$y, bank_cost_pred))

# sensitivity
sens <- sum(bank_test$y=="yes" & bank_cost_pred=="yes")/sum(bank_test$y=="yes")
sens

```
Combine predictions made from the test data using this final model, C5.0 with cost function, into the bank test data and present the predictions. From the result, the classes of the first 6 examples in the test data are all nos, and the predictions for those are also all nos. The model predicts them correctly.

```{r}
bank_test$prediction=bank_cost_pred

head(bank_test)

```








